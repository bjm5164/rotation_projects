{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On arbor synapse distributions\n",
    "* Now that we have synapses annotated for neurons, one of the analyses we want to do is look at the spatial distribution of synapses on our neuron of interest. \n",
    "* To do this, we need a few things:\n",
    "1. A way to measure distances along arbors and calculate branch points.\n",
    "2. A way to associate synapses with our neuron.\n",
    "\n",
    "### Here we will use meshwork to calculate synapse density along our arbors \n",
    "* To facilitate some python practice, some of the data table formats used here will not necessarily be the ones used for your synapse tables / soma tables. \n",
    "* Try to reformat your data frames to get things to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from annotationframeworkclient import FrameworkClient\n",
    "import nglui\n",
    "from matplotlib import cm\n",
    "from nglui.statebuilder import *\n",
    "from matplotlib import pyplot as plt\n",
    "import pymaid\n",
    "from cloudvolume import CloudVolume\n",
    "from meshparty import trimesh_io, meshwork,mesh_filters,trimesh_vtk\n",
    "from concurrent import futures\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "def deserialize_pts(pt_string):\n",
    "    vals = re.findall('\\d+',pt_string)\n",
    "    return([int(vals[0]),int(vals[1]),int(vals[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish FrameworkClient and CloudVolume objects to download tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.home() / 'cloudvolume' / 'secrets'/'chunkedgraph-secret.json') as f:\n",
    "        tokens = json.load(f)\n",
    "\n",
    "with open(Path.home() / 'cloudvolume' / 'segmentations.json') as f:\n",
    "        cv_paths = json.load(f)\n",
    "        \n",
    "#Client object\n",
    "dev_token = tokens['dev']\n",
    "auth_token = tokens['api']\n",
    "datastack_name = 'vnc_v0' # from https://api.zetta.ai/wclee/info/\n",
    "\n",
    "client = FrameworkClient(\n",
    "    datastack_name,\n",
    "    server_address = \"https://api.zetta.ai/wclee\",\n",
    "    auth_token = auth_token\n",
    ")\n",
    "\n",
    "# CloudVolume object\n",
    "cv = CloudVolume(cv_paths['Dynamic_V1']['url'],use_https=True,secrets=dev_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we need to do two things:\n",
    "1. Download our synapse table.\n",
    "2. Download our mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will use an already materialized synapse table and a 10B neuron. \n",
    "- The methods `.download_annotation_table` and `.generate_soma_table` should be familiar.\n",
    "- If you do not have a soma table that includes your neuron, generate a DataFrame that includes a `pt_root_id` column containing the segment ID of your neuron and a `pt_position` column with the soma coordinates.\n",
    "- To get a synapse table, adapt your code to generate a DataFrame from your synapse table with the columns `pre_pt` and `post_pt` which should be `[x,y,z]` coordinates for your synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_annotation_table(client,table_name,ids=range(1000)):\n",
    "    entries = client.annotation.get_annotation(table_name,ids)\n",
    "    annotation_table = pd.DataFrame(entries)\n",
    "    \n",
    "    return(annotation_table)\n",
    "\n",
    "def generate_soma_table(annotation_table,\n",
    "                        segmentation_version='Dynamic_V1',\n",
    "                        resolution=np.array([4.3,4.3,45]),\n",
    "                        token=None):\n",
    "    ''' Generate a soma table used for microns analysis. This is the workaround for a materialization engine\n",
    "    Args:\n",
    "        annotation_table: pd.DataFrame, output from download_cell_table. Retreived from the annotation engine.\n",
    "        segmentation_version: str, Currently we have 4 for FANC. Two flat segmentations (\"Flat_1\" and \"Flat_2\") and two dynamic (\"Dynamic_V1/V2\"). \n",
    "                              This will only work if you have a segmentations.json in your cloudvolume folder. See examples for format.\n",
    "        resolution: np.array, Resolution of the mip0 coordinates of the version (not necessarily the same as the segmentation layer resolution).\n",
    "                              For all but the original FANC segmentation, this will be [4.3,4.3,45]\n",
    "        token: str, currently, CloudVolume requires a workaround for passing google secret tokens. This won't work unless you edit your cloudvolume \n",
    "                              file to remove the check for hexidecimal formatting of tokens. Updates should be coming to fix this. \n",
    "        '''\n",
    "\n",
    "    soma_table = pd.DataFrame(columns=['name','cell_type',\n",
    "                                       'pt_position','pt_root_id',\n",
    "                                       'soma_x_nm','soma_y_nm','soma_z_nm',\n",
    "                                       'found'])\n",
    "    with open(Path.home() / 'cloudvolume' / 'segmentations.json') as f:\n",
    "            cloud_paths = json.load(f)\n",
    "    if 'Dynamic' in segmentation_version:\n",
    "        cv = CloudVolume(cloud_paths[segmentation_version]['url'],agglomerate=True,use_https=True,secrets=token)\n",
    "    else:\n",
    "        cv = CloudVolume(cloud_paths[segmentation_version]['url'],use_https=True,secrets=token)\n",
    "        \n",
    "    seg_ids = seg_from_pt(annotation_table.pt_position,cv)\n",
    "    \n",
    "    soma_table.name = annotation_table.tag\n",
    "    soma_table.pt_position = annotation_table.pt_position\n",
    "    soma_table.pt_root_id = seg_ids\n",
    "    soma_table.soma_x_nm = np.array([i[0] for i in annotation_table.pt_position]) * resolution[0]\n",
    "    soma_table.soma_y_nm = np.array([i[1] for i in annotation_table.pt_position]) * resolution[1]\n",
    "    soma_table.soma_z_nm = np.array([i[2] for i in annotation_table.pt_position]) * resolution[2]\n",
    "    \n",
    "    return(soma_table)\n",
    "\n",
    "def seg_from_pt(pts,vol,image_res=np.array([4.3,4.3,45]),max_workers=4):\n",
    "    ''' Get segment ID at a point. Default volume is the static segmentation layer for now. \n",
    "    Args:\n",
    "        pts (list): list of 3-element np.arrays of MIP0 coordinates\n",
    "        vol_url (str): cloud volume url\n",
    "    Returns:\n",
    "        list, segment_ID at specified point '''\n",
    "    \n",
    "    \n",
    "    seg_mip = vol.scale['resolution']\n",
    "    res = seg_mip / image_res\n",
    "\n",
    "    pts_scaled = [pt // res for pt in pts]\n",
    "    results = []\n",
    "    with futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        point_futures = [ex.submit(lambda pt,vol: vol[list(pt)][0][0][0][0], k,vol) for k in pts_scaled]\n",
    "        \n",
    "        for f in futures.as_completed(point_futures):\n",
    "            results=[f.result() for f in point_futures]\n",
    "       \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get soma table:\n",
    "table = download_annotation_table(client,'Hemilineages')\n",
    "table_mat = generate_soma_table(table,token=tokens['dev'])\n",
    "soma_df = table_mat.loc[table_mat.name == '10B']\n",
    "# Load synapse table (UPDATE THIS FOR YOURSELF) It doesn't need to be from a CSV, it can be directly from the annotation engine. \n",
    "synapse_filename = None\n",
    "inputs = pd.read_csv(filename)\n",
    "inputs.pre_pt = [deserialize_pts(i) for i in inputs.pre_pt]\n",
    "inputs.post_pt = [deserialize_pts(i) for i in inputs.post_pt]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply a segment ID (your neuron of interest) and download the mesh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_id = 648518346706280104\n",
    "mesh = cv.mesh.get(neuron_id,use_byte_offsets=True)[neuron_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format for meshwork\n",
    "- Normally meshparty has its own i/o method, but it doesn't work for us, so we download a cloudvolume mesh and convert to a meshparty mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_mesh = trimesh_io.Mesh(mesh.vertices,mesh.faces)\n",
    "\n",
    "mp_mesh.merge_large_components(size_threshold=100,\n",
    "                                    max_dist=1000,\n",
    "                                    dist_step=500)\n",
    "in_comp = mesh_filters.filter_largest_component(mp_mesh)\n",
    "mesh_anchor = mp_mesh.apply_mask(in_comp)\n",
    "\n",
    "neuron = meshwork.Meshwork(mesh_anchor, seg_id=neuron_id,voxel_resolution=[4.3,4.3,45])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations\n",
    "- Meshwork has a bunch of cool methods for adding any type of annotation to our mesh object. While this may not be perfect for generating perfect skeletons as the whole process relies on meshparty, it is great for analysis. \n",
    "- Lets add our synapses (in the case of this example, input synapses) and a soma annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.add_annotations('syn_in', inputs, point_column='post_pt')\n",
    "neuron.add_annotations('soma_pt', soma_df.query('pt_root_id == @neuron_id').copy(), point_column='pt_position', anchored=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize our mesh and synapse annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_actor = trimesh_vtk.point_cloud_actor(neuron.anno.syn_in.points, size=200, color=(0.2, 0.9, 0.9))\n",
    "mesh_actor = trimesh_vtk.mesh_actor(neuron.mesh, opacity=.1, color=(0.7, 0.7, 0.7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to skeletonize our mesh. \n",
    "- Let's do that and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.skeletonize_mesh(soma_pt=neuron.anno.soma_pt.points[0],invalidation_distance=5000)\n",
    "skel_actor = trimesh_vtk.skeleton_actor(neuron.skeleton, line_width=3, color=(0,0,0))\n",
    "trimesh_vtk.render_actors([skel_actor, mesh_actor,syn_actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Analysis\n",
    "- MeshWork has a few super useful algorithms including `linear_density` which will calculate the density of any annotation. \n",
    "- Let's calculate the input density and plot a mesh, then look at a histogram of densities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = neuron.linear_density(neuron.anno.syn_in.mesh_index, 5000, normalize=True, exclude_root=True)\n",
    "rho[np.isinf(rho)] = 0\n",
    "ma = trimesh_vtk.mesh_actor(neuron.mesh, vertex_colors=(1000*rho-0.5), opacity=1)\n",
    "trimesh_vtk.render_actors([ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rho,range=[.0001,.0025])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's look at synapses on distinct arbors. \n",
    "- If a branch point exists between synapses, they are on distinct arbors so:\n",
    "1. Find branch points.\n",
    "2. Get synapse locations.\n",
    "3. Find synapses distal to all branch points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_points = neuron.branch_points\n",
    "synapses = neuron.anno.syn_in.mesh_index\n",
    "arbors = [neuron.downstream_of(i) for i in branch_points]\n",
    "## ... you try the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatively, we can use branching order to prune our neuron and look at where synapses exist. \n",
    "* Branching order comes in a couple flavors:\n",
    "  1. Count the branch points from the root to the node. (basic)\n",
    "  2. Count the number of children of a node. (strahler) This one is more abstract, but arguably better: https://en.wikipedia.org/wiki/Strahler_number\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch_mask(mw_nrn,\n",
    "                method = 'basic',\n",
    "                min_order = 1,\n",
    "                max_order=None):\n",
    "    ''' Apply a branching order mask to your neuron\n",
    "    args:\n",
    "    mw_nrn: meshwork neuron object\n",
    "    method: str, basic or strahler, default is basic\n",
    "    min_order: int, minimum branching order to include. Needs to be scaled depending on method. \n",
    "    max_order: int, maximum branching order to include. Needs to be scaled depending on method. \n",
    "    returns:\n",
    "    mask: bool, mask for all vertices of your mesh. \n",
    "    '''\n",
    "    if method == 'basic':\n",
    "        si = meshwork.algorithms.branch_order(mw_nrn)\n",
    "    elif method == 'strahler':\n",
    "        si = meshwork.algorithms.strahler_order(mw_nrn)\n",
    "    else:\n",
    "        return('Wrong method')\n",
    "\n",
    "    if max_order is None:\n",
    "        max_order = np.max(si)\n",
    "    mask = [min_order<=x<=max_order for x in si]\n",
    "    return(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.reset_mask()\n",
    "neuron.apply_mask(branch_mask(neuron,min_order=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = trimesh_vtk.mesh_actor(neuron.mesh, opacity=1)\n",
    "trimesh_vtk.render_actors([ma,syn_actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to apply this:\n",
    "1. Do particular cell types synapse on different regions of the neuron?\n",
    "   - Different branches, different branch orders (primary neurite vs twig, etc).\n",
    "2. Do individual neurons cluster their synapses on particular arbors?\n",
    "   - Either by density or by # of arbors they synapse onto, etc. \n",
    "3. Lots of other things... let me know if there are other tools that might help!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connectomics_analysis",
   "language": "python",
   "name": "connectomics_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
